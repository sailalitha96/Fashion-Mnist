{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fritz.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "M72OaOgoIewb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import Input, merge\n",
        "from keras.layers import Convolution2D , concatenate ,Conv2D,Dense\n",
        "from keras.layers import Activation,Dropout, GlobalAveragePooling2D,BatchNormalization,SeparableConv2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import  to_categorical\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.contrib.slim as slim\n",
        "from keras.layers.core import Dense,Dropout,Activation,Flatten,Lambda\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q13lZIidIhvi",
        "colab_type": "code",
        "outputId": "453aaa98-0586-4c6e-b500-16f71d2f980d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "x_train = x_train/ 255.0\n",
        "\n",
        "x_test = x_test/255.0\n",
        "\n",
        "# Add empty color dimension\n",
        "x_train = np.expand_dims(x_train, -1)  # shape: (num_samples, 28, 28, 1)\n",
        "x_test = np.expand_dims(x_test, -1) # shape: (num_samples, 1)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "print(y_train.shape,y_test.shape,x_train.shape,x_test.shape)\n",
        "print(type(x_train))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 3us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n",
            "(60000, 10) (10000, 10) (60000, 28, 28, 1) (10000, 28, 28, 1)\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E9J6MrYUIrXC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# squeezenet has bottle neck modules- firmodules\n",
        "def build_squeezenet(input_shape=(28, 28, 1), n_classes=10):\n",
        "    \n",
        "    input_layer = Input(shape = input_shape)\n",
        "    \n",
        "    out = Conv2D(96, kernel_size =(3, 3), activation='relu')(input_layer)\n",
        "    # no mxpooling done since small images \n",
        "    out = fire_module(out,squeeze =16 , expansion =64)\n",
        "    out = fire_module(out,squeeze = 16 , expansion=64)\n",
        "    \n",
        "    out = fire_module(out,squeeze= 32,expansion = 128)\n",
        "    out = fire_module(out,squeeze= 32,expansion = 128)\n",
        "    \n",
        "    out = fire_module(out , squeeze = 48 ,expansion=192)\n",
        "    out = fire_module(out,squeeze = 48 , expansion = 192)\n",
        "    \n",
        "    out = fire_module(out,squeeze = 64 , expansion = 256)\n",
        "    out = fire_module(out,squeeze = 64 , expansion = 256)\n",
        "    \n",
        "    out = Dropout(0.2)(out)\n",
        "    \n",
        "    out = Conv2D(10,kernel_size=(1,1),padding='valid',activation='relu')(out)\n",
        "    out = GlobalAveragePooling2D()(out)\n",
        "    out = Dense(10, activation=\"softmax\")(out)\n",
        "    \n",
        "    model = Model(input_layer, out, name='squeezenet')\n",
        "    return model \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yerwuaw7Izrl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fire_module(input_layer, squeeze =16 , expansion =32):\n",
        "\n",
        "# a definition for fire module et.al https://github.com/rcmalli/keras-squeezenet/\n",
        "# inspiration\n",
        "# squeezing using 1x1 kernel and expansion with 1x1 and 3x3. Concatenate the output to get best result.\n",
        "\n",
        "    fire_sq = Conv2D(squeeze,1,1,activation='relu')(input_layer)\n",
        "    fire_exp1 = Conv2D(expansion ,kernel_size=(1,1),activation='relu',padding='valid')(fire_sq)\n",
        "    fire_exp2 = Conv2D(expansion ,kernel_size=(3,3),activation='relu',padding='same')(fire_sq)\n",
        "    out = concatenate([fire_exp1,fire_exp2], axis=3)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S4QMfRUOI2Ut",
        "colab_type": "code",
        "outputId": "bfb00111-2a1f-4056-b911-a1a77c69c2bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        }
      },
      "cell_type": "code",
      "source": [
        "model = build_squeezenet(input_shape=(28, 28, 1), n_classes=10)\n",
        "# model_dw = build_squeezenet_depthwise()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(lr=1e-3), loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "# model.summary()\n",
        "model.fit(x=x_train, \n",
        "            y=y_train, \n",
        "            batch_size=128,\n",
        "            epochs=10, \n",
        "            verbose=1,  \n",
        "            validation_split=0.2,\n",
        "            validation_data=(x_test,y_test), \n",
        "            shuffle=True)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), activation=\"relu\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), activation=\"relu\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (1, 1), activation=\"relu\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\")`\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 104s 2ms/step - loss: 1.0604 - acc: 0.5932 - val_loss: 0.5716 - val_acc: 0.7804\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.5055 - acc: 0.8144 - val_loss: 0.4616 - val_acc: 0.8401\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.4022 - acc: 0.8558 - val_loss: 0.3927 - val_acc: 0.8546\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.3553 - acc: 0.8713 - val_loss: 0.3411 - val_acc: 0.8793\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.3240 - acc: 0.8840 - val_loss: 0.3177 - val_acc: 0.8851\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.3056 - acc: 0.8899 - val_loss: 0.3356 - val_acc: 0.8842\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.2912 - acc: 0.8962 - val_loss: 0.3149 - val_acc: 0.8914\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.2751 - acc: 0.9010 - val_loss: 0.2916 - val_acc: 0.8993\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.2638 - acc: 0.9049 - val_loss: 0.2758 - val_acc: 0.8997\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.2569 - acc: 0.9076 - val_loss: 0.2882 - val_acc: 0.9001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f28b78a4390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "S3wZ1yxiLcMQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J4-1IJWlN6h2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#building squeezenet \n",
        "def build_squeezenet_depthwise(input_shape, width_multiplier = 1):\n",
        "    \n",
        "    # call depthwise convolution - step 1 \n",
        "    # call pointwise conolution - step 2 \n",
        "    \n",
        "\n",
        "    input_layer = Input((input_shape))\n",
        "    \n",
        "    # the spatial convolutional network is 1x3 and then 3x1 . Implementd in the below function \n",
        "\n",
        "    x = Convolution2D(int(32), (3, 3), padding='same')(input_layer)\n",
        "    # each layer is passed through a bath normalization , helps in normalizing .\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "\n",
        "    x = DepthwiseConvolution2D(x,int(32), padding='same')\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(int(64), (1, 1), strides=(1, 1), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = DepthwiseConvolution2D(x,int(64), padding='same')\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(int(128), (1, 1), strides=(1, 1), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = DepthwiseConvolution2D(x,int(128), padding='same')\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(int(128) ,(1, 1), strides=(1, 1), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = DepthwiseConvolution2D(x,int(128), padding='same')\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(int(256), (1, 1), strides=(1, 1), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = DepthwiseConvolution2D(x,int(256), padding='same')\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(int(256), (1, 1), strides=(1, 1), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = DepthwiseConvolution2D(x,int(256), padding='same')\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(int(512), (1, 1), strides=(1, 1), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    x = Conv2D(10,kernel_size=(1,1),padding='valid',activation='relu')(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    \n",
        "   \n",
        "    x = Dense(10, activation='softmax')(x)\n",
        "    \n",
        "    \n",
        "    model = Model(input_layer, x, name='mobilenet')\n",
        "    return model \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "def DepthwiseConvolution2D( inputs , filter_size, width=1, padding='same') :\n",
        "    \n",
        "    # call depthwise convolution - step 1 \n",
        "    # call pointwise conolution - step 2 \n",
        "    \n",
        "    # the seperable convoltuion makes 3x3 filters \n",
        "    #applied first 1x3 and then 3x1. \n",
        "    \n",
        "    x = SeparableConv2D(filter_size, kernel_size=(3,3) , strides = (1, 1),depth_multiplier= 1)(inputs)\n",
        "#     out = slim.separable_convolution2d(inputs,num_outputs=None,\n",
        "#                                                   stride=(2,2),\n",
        "#                                                   padding =\"SAME\",\n",
        "#                                                   depth_multiplier=1,\n",
        "#                                                   kernel_size=[3, 3])\n",
        "    \n",
        "    num_pwc_filters = int(filter_size*width)\n",
        "    \n",
        "#     batch =slim.batch_norm(out)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "\n",
        "    \n",
        "#     point_out=  slim.convolution2d(batch,num_pwc_filters,kernel_size=[1, 1])\n",
        "    x = Convolution2D(filter_size,kernel_size =(1, 1), strides=(1, 1), padding='same')(x)\n",
        "   \n",
        "    x = BatchNormalization()(x)\n",
        "    print(x.shape)\n",
        "\n",
        "    return x\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UIuywPoCN8nJ",
        "colab_type": "code",
        "outputId": "e5003597-131d-4966-be8a-b54ed30083fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        }
      },
      "cell_type": "code",
      "source": [
        "model_dw = build_squeezenet_depthwise(input_shape= (28,28,1))\n",
        "\n",
        "model_dw.compile(\n",
        "    optimizer=Adam(lr=1e-3), loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "# model.summary()\n",
        "model_dw.fit(x=x_train, \n",
        "            y=y_train, \n",
        "            batch_size=128,\n",
        "            epochs=10, \n",
        "            verbose=1,  \n",
        "            validation_split=0.2,\n",
        "            validation_data=(x_test,y_test), \n",
        "            shuffle=True)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 26, 26, 32)\n",
            "(?, 24, 24, 64)\n",
            "(?, 22, 22, 128)\n",
            "(?, 20, 20, 128)\n",
            "(?, 18, 18, 256)\n",
            "(?, 16, 16, 256)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 113s 2ms/step - loss: 0.6575 - acc: 0.7685 - val_loss: 0.7191 - val_acc: 0.8092\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 96s 2ms/step - loss: 0.3271 - acc: 0.8824 - val_loss: 0.6079 - val_acc: 0.8053\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 96s 2ms/step - loss: 0.2812 - acc: 0.8991 - val_loss: 0.6045 - val_acc: 0.8122\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 96s 2ms/step - loss: 0.2556 - acc: 0.9097 - val_loss: 0.4376 - val_acc: 0.8555\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 96s 2ms/step - loss: 0.2376 - acc: 0.9153 - val_loss: 0.3272 - val_acc: 0.8989\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 96s 2ms/step - loss: 0.2205 - acc: 0.9212 - val_loss: 0.2919 - val_acc: 0.9036\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 96s 2ms/step - loss: 0.2099 - acc: 0.9244 - val_loss: 0.2945 - val_acc: 0.9002\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 96s 2ms/step - loss: 0.2001 - acc: 0.9283 - val_loss: 0.3265 - val_acc: 0.8920\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 96s 2ms/step - loss: 0.1895 - acc: 0.9330 - val_loss: 0.3659 - val_acc: 0.8836\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 96s 2ms/step - loss: 0.1809 - acc: 0.9346 - val_loss: 0.3624 - val_acc: 0.8954\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f29d10b1c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "5Pk9EU4UJ22T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Summary of the models have been given below. I believe that Mobile net performs better than the squeezenet version given above since, the spatial convolution preserves features better than the Squeeze model and the convoultional redcues complexity.\n",
        "\n",
        "\n",
        "Squeezenet is preserving accuracy with few parameters.The Squeeze Module decreases the number of input channels significantly.\n",
        "The Expand Module then increases the number of input channels again.\n",
        "\n",
        "\n",
        "\n",
        "MobileNet -MobileNet  is a stack of the separable convolution modules which are composed of depthwise conv and conv1x1 (pointwise conv). It uses layers such as depthwise convolution  which significantly reduces the computational cost by omitting convolution in channel domain.I have used the V1 version. \n",
        "\n",
        "Given more time I will do hyperparamter tuning and implement on larger size images to check for spatial reductions. Applying in different datasets with more ambigous data. \n",
        "\n",
        "It can be seen that although Mobilenet performs better it is still smaller in size compared to Squeezenet. Hence it is a matter of tradeoff, we could inreality tune squeeenet and make it equalized. \n",
        "\n",
        "If the intention is make Mobilenet smaller , we could apply L1 norm to eleiminate a few parameters and make it smalers"
      ]
    },
    {
      "metadata": {
        "id": "TwkOuKUdIPTl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2310
        },
        "outputId": "985607ca-b36b-489c-9abb-2a5eb5a2283a"
      },
      "cell_type": "code",
      "source": [
        "model_dw.summary()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_23 (InputLayer)        (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_120 (Conv2D)          (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_197 (Bat (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_142 (Activation)  (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_32 (Separab (None, 26, 26, 32)        1344      \n",
            "_________________________________________________________________\n",
            "batch_normalization_198 (Bat (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_121 (Conv2D)          (None, 26, 26, 32)        1056      \n",
            "_________________________________________________________________\n",
            "batch_normalization_199 (Bat (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "batch_normalization_200 (Bat (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_143 (Activation)  (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_122 (Conv2D)          (None, 26, 26, 64)        2112      \n",
            "_________________________________________________________________\n",
            "batch_normalization_201 (Bat (None, 26, 26, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_144 (Activation)  (None, 26, 26, 64)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_33 (Separab (None, 24, 24, 64)        4736      \n",
            "_________________________________________________________________\n",
            "batch_normalization_202 (Bat (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_123 (Conv2D)          (None, 24, 24, 64)        4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_203 (Bat (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "batch_normalization_204 (Bat (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_145 (Activation)  (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_124 (Conv2D)          (None, 24, 24, 128)       8320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_205 (Bat (None, 24, 24, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_146 (Activation)  (None, 24, 24, 128)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_34 (Separab (None, 22, 22, 128)       17664     \n",
            "_________________________________________________________________\n",
            "batch_normalization_206 (Bat (None, 22, 22, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_125 (Conv2D)          (None, 22, 22, 128)       16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_207 (Bat (None, 22, 22, 128)       512       \n",
            "_________________________________________________________________\n",
            "batch_normalization_208 (Bat (None, 22, 22, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_147 (Activation)  (None, 22, 22, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_126 (Conv2D)          (None, 22, 22, 128)       16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_209 (Bat (None, 22, 22, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_148 (Activation)  (None, 22, 22, 128)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_35 (Separab (None, 20, 20, 128)       17664     \n",
            "_________________________________________________________________\n",
            "batch_normalization_210 (Bat (None, 20, 20, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_127 (Conv2D)          (None, 20, 20, 128)       16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_211 (Bat (None, 20, 20, 128)       512       \n",
            "_________________________________________________________________\n",
            "batch_normalization_212 (Bat (None, 20, 20, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_149 (Activation)  (None, 20, 20, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_128 (Conv2D)          (None, 20, 20, 256)       33024     \n",
            "_________________________________________________________________\n",
            "batch_normalization_213 (Bat (None, 20, 20, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_150 (Activation)  (None, 20, 20, 256)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_36 (Separab (None, 18, 18, 256)       68096     \n",
            "_________________________________________________________________\n",
            "batch_normalization_214 (Bat (None, 18, 18, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_129 (Conv2D)          (None, 18, 18, 256)       65792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_215 (Bat (None, 18, 18, 256)       1024      \n",
            "_________________________________________________________________\n",
            "batch_normalization_216 (Bat (None, 18, 18, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_151 (Activation)  (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_130 (Conv2D)          (None, 18, 18, 256)       65792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_217 (Bat (None, 18, 18, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_152 (Activation)  (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_37 (Separab (None, 16, 16, 256)       68096     \n",
            "_________________________________________________________________\n",
            "batch_normalization_218 (Bat (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_131 (Conv2D)          (None, 16, 16, 256)       65792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_219 (Bat (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "batch_normalization_220 (Bat (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_153 (Activation)  (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_132 (Conv2D)          (None, 16, 16, 512)       131584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_221 (Bat (None, 16, 16, 512)       2048      \n",
            "_________________________________________________________________\n",
            "activation_154 (Activation)  (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_133 (Conv2D)          (None, 16, 16, 10)        5130      \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_11  (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 626,200\n",
            "Trainable params: 618,264\n",
            "Non-trainable params: 7,936\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U_HV5DRFLeiB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1598
        },
        "outputId": "17ca0c29-d26e-4837-bb06-7616a0c33f2b"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_25 (InputLayer)           (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 26, 26, 96)   960         input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 26, 26, 16)   1552        conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 26, 26, 64)   1088        conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 26, 26, 64)   9280        conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 26, 26, 128)  0           conv2d_161[0][0]                 \n",
            "                                                                 conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 26, 26, 16)   2064        concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 26, 26, 64)   1088        conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 26, 26, 64)   9280        conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 26, 26, 128)  0           conv2d_164[0][0]                 \n",
            "                                                                 conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 26, 26, 32)   4128        concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 26, 26, 128)  4224        conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 26, 26, 128)  36992       conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 26, 26, 256)  0           conv2d_167[0][0]                 \n",
            "                                                                 conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 26, 26, 32)   8224        concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 26, 26, 128)  4224        conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 26, 26, 128)  36992       conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 26, 26, 256)  0           conv2d_170[0][0]                 \n",
            "                                                                 conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 26, 26, 48)   12336       concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 26, 26, 192)  9408        conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 26, 26, 192)  83136       conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 26, 26, 384)  0           conv2d_173[0][0]                 \n",
            "                                                                 conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 26, 26, 48)   18480       concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 26, 26, 192)  9408        conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 26, 26, 192)  83136       conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 26, 26, 384)  0           conv2d_176[0][0]                 \n",
            "                                                                 conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 26, 26, 64)   24640       concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 26, 26, 256)  16640       conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 26, 26, 256)  147712      conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 26, 26, 512)  0           conv2d_179[0][0]                 \n",
            "                                                                 conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 26, 26, 64)   32832       concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 26, 26, 256)  16640       conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 26, 26, 256)  147712      conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 26, 26, 512)  0           conv2d_182[0][0]                 \n",
            "                                                                 conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 26, 26, 512)  0           concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_13 (Gl (None, 512)          0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 10)           5130        global_average_pooling2d_13[0][0]\n",
            "==================================================================================================\n",
            "Total params: 727,306\n",
            "Trainable params: 727,306\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}